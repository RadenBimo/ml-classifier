{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./vocab.txt',)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "model = AutoModel.from_pretrained(\"indolem/indobert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([  101., 11999.,   102.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.])],\n",
       " [tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.])])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunk_token(tokens, chunksize = 512):    \n",
    "    # split into chunks of 510 tokens, we also convert to list (default is tuple which is immutable)\n",
    "    input_id_chunks = list(tokens['input_ids'][0].split(chunksize - 2))\n",
    "    mask_chunks = list(tokens['attention_mask'][0].split(chunksize - 2))\n",
    "    \n",
    "    return input_id_chunks, mask_chunks\n",
    "\n",
    "def clssep_padding(input_id_chunks, mask_chunks, chunksize = 512):\n",
    "    # loop through each chunk\n",
    "    for i in range(len(input_id_chunks)):\n",
    "    \n",
    "        # add CLS and SEP tokens to input IDs\n",
    "        input_id_chunks[i] = torch.cat([\n",
    "            torch.tensor([101]), input_id_chunks[i], torch.tensor([102])\n",
    "        ])\n",
    "\n",
    "        # add attention tokens to attention mask\n",
    "        mask_chunks[i] = torch.cat([\n",
    "            torch.tensor([1]), mask_chunks[i], torch.tensor([1])\n",
    "        ])\n",
    "\n",
    "        # get required padding length\n",
    "        pad_len = chunksize - input_id_chunks[i].shape[0]\n",
    "        # check if tensor length satisfies required chunk size\n",
    "        if pad_len > 0:\n",
    "            # if padding length is more than 0, we must add padding\n",
    "            input_id_chunks[i] = torch.cat([\n",
    "                input_id_chunks[i], torch.Tensor([0] * pad_len)\n",
    "            ])\n",
    "            mask_chunks[i] = torch.cat([\n",
    "                mask_chunks[i], torch.Tensor([0] * pad_len)\n",
    "            ])\n",
    "\n",
    "    return input_id_chunks, mask_chunks\n",
    "    \n",
    "\n",
    "def tokenizing(sentences):\n",
    "    tokens = tokenizer.encode_plus(\n",
    "        txt, \n",
    "        add_special_tokens=False,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_id_chunks, mask_chunks = chunk_token(tokens)\n",
    "    id_chunks, mask_chunks= clssep_padding(input_id_chunks, mask_chunks)\n",
    "\n",
    "    return id_chunks, mask_chunks\n",
    "\n",
    "tokenizing(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset/email_spam_indo.csv\")\n",
    "\n",
    "X= df[\"Pesan\"].values\n",
    "labels = df['Kategori'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Dataset/health.csv\",sep=\";\")[[\"text\",\"category\"]]\n",
    "X=df[\"text\"].values\n",
    "labels = df['category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Callable, Optional, Tuple, Union\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from transformers import BertModel, BertTokenizer, DistilBertModel, DistilBertTokenizer\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim, nn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "#from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import metrics as sk_metrics\n",
    "\n",
    "def split_random(train: float, val: float, test: float) -> str:\n",
    "    if train + val + test != 1.0:\n",
    "        raise ValueError(\"train + val + test  must equal 1\")\n",
    "    rand_num = np.random.rand()\n",
    "    \n",
    "    if rand_num  <= train:\n",
    "        return \"train\"\n",
    "    elif rand_num <= train + val:\n",
    "        return \"val\"\n",
    "    else:\n",
    "        return \"test\"\n",
    "    \n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        max_length: int = 60,\n",
    "        embedding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        #self.model.eval()\n",
    "        self.max_length = max_length\n",
    "        self.embedding_func = embedding_func\n",
    "\n",
    "        if self.embedding_func is None:\n",
    "            self.embedding_func = lambda x: x[0][:, 0, :].squeeze()\n",
    "\n",
    "    def _tokenize(self, text: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Tokenize the text with the provided tokenizer\n",
    "        tokenized_text = self.tokenizer.encode_plus(\n",
    "            text, add_special_tokens=True, max_length=self.max_length,truncation=True\n",
    "        )[\"input_ids\"]\n",
    "        \n",
    "        # padding\n",
    "        padded_text = tokenized_text + [0]*(self.max_length-len(tokenized_text))\n",
    "\n",
    "        # Create an attention mask telling BERT to use all words and ignore padded values\n",
    "        attention_mask = np.where(np.array(padded_text) != 0, 1, 0)\n",
    "\n",
    "        # bert takes in a batch so we need to unsqueeze the rows\n",
    "        return (\n",
    "            torch.tensor(padded_text).unsqueeze(0),\n",
    "            torch.tensor(attention_mask).unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    def _tokenize_and_predict(self, text: str) -> torch.Tensor:\n",
    "        tokenized, attention_mask = self._tokenize(text)\n",
    "\n",
    "        embeddings = self.model(tokenized, attention_mask)\n",
    "        return self.embedding_func(embeddings)\n",
    "\n",
    "    def transform(self, text: List[str]):\n",
    "        if isinstance(text, pd.Series):\n",
    "            text = text.tolist()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            return torch.stack([self._tokenize_and_predict(string) for string in text])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"No fitting necessary so we just return ourselves\"\"\"\n",
    "        return self\n",
    "    \n",
    "def calculate_classification_metrics(\n",
    "    y_true: np.array,\n",
    "    y_pred: np.array,\n",
    "    average: Optional[str] = None,\n",
    "    return_df: bool = True,\n",
    ") -> Union[Dict[str, float], pd.DataFrame]:\n",
    "    \"\"\"Computes f1, precision, recall, precision, kappa, accuracy, and support\n",
    "\n",
    "    Args:\n",
    "        y_true: The true labels\n",
    "        y_pred: The predicted labels\n",
    "        average: How to average multiclass results\n",
    "\n",
    "    Returns:\n",
    "        Either a dataframe of the performance metrics or a single dictionary\n",
    "    \"\"\"\n",
    "    labels = unique_labels(y_true, y_pred)\n",
    "\n",
    "    # get results\n",
    "    precision, recall, f_score, support = sk_metrics.precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=labels, average=average\n",
    "    )\n",
    "\n",
    "    kappa = sk_metrics.cohen_kappa_score(y_true, y_pred, labels=labels)\n",
    "    accuracy = sk_metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # create a pandas DataFrame\n",
    "    if return_df:\n",
    "        results = pd.DataFrame(\n",
    "            {\n",
    "                \"class\": labels,\n",
    "                \"f_score\": f_score,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"support\": support,\n",
    "                \"kappa\": kappa,\n",
    "                \"accuracy\": accuracy,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        results = {\n",
    "            \"f1\": f_score,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"kappa\": kappa,\n",
    "            \"accuracy\": accuracy,\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#classifier = svm.LinearSVC(C=1.0, class_weight=\"balanced\")\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "dbt = BertTransformer(DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\"),\n",
    "                      DistilBertModel.from_pretrained(\"distilbert-base-uncased\"),\n",
    "                      embedding_func=lambda x: x[0][:, 0, :].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_ = encoder.fit_transform(y_train)\n",
    "y_test_ = encoder.transform(y_test)\n",
    "y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 BertTransformer(embedding_func=&lt;function &lt;lambda&gt; at 0x000002346E5FA1F0&gt;,\n",
       "                                 model=DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transform...\n",
       "\t101: AddedToken(&quot;[CLS]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(&quot;[SEP]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(&quot;[MASK]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "})),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 BertTransformer(embedding_func=&lt;function &lt;lambda&gt; at 0x000002346E5FA1F0&gt;,\n",
       "                                 model=DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transform...\n",
       "\t101: AddedToken(&quot;[CLS]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(&quot;[SEP]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(&quot;[MASK]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "})),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BertTransformer</label><div class=\"sk-toggleable__content\"><pre>BertTransformer(embedding_func=&lt;function &lt;lambda&gt; at 0x000002346E5FA1F0&gt;,\n",
       "                model=DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): Module...\n",
       "\t100: AddedToken(&quot;[UNK]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(&quot;[CLS]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(&quot;[SEP]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(&quot;[MASK]&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 BertTransformer(embedding_func=<function <lambda> at 0x000002346E5FA1F0>,\n",
       "                                 model=DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transform...\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "})),\n",
       "                ('classifier', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", dbt),\n",
    "        (\"classifier\", classifier),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI11\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masalah Akses dan Keamanan Data</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masalah Pengelolaan Informasi Vaksinasi</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masalah Terkait Check-in dan Riwayat Kunjungan</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masalah Terkait Pembelian Obat dan Check-in Lo...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               class   f_score  precision  \\\n",
       "0                    Masalah Akses dan Keamanan Data  0.000000        0.0   \n",
       "1            Masalah Pengelolaan Informasi Vaksinasi  0.666667        0.5   \n",
       "2     Masalah Terkait Check-in dan Riwayat Kunjungan  0.800000        1.0   \n",
       "3  Masalah Terkait Pembelian Obat dan Check-in Lo...  0.500000        1.0   \n",
       "\n",
       "     recall  support     kappa  accuracy  \n",
       "0  0.000000        0  0.489362     0.625  \n",
       "1  1.000000        2  0.489362     0.625  \n",
       "2  0.666667        3  0.489362     0.625  \n",
       "3  0.333333        3  0.489362     0.625  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "calculate_classification_metrics(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI11\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masalah Akses dan Keamanan Data</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masalah Pengelolaan Informasi Vaksinasi</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masalah Terkait Check-in dan Riwayat Kunjungan</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masalah Terkait Pembelian Obat dan Check-in Lo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               class   f_score  precision  \\\n",
       "0                    Masalah Akses dan Keamanan Data  0.000000        0.0   \n",
       "1            Masalah Pengelolaan Informasi Vaksinasi  0.571429        0.5   \n",
       "2     Masalah Terkait Check-in dan Riwayat Kunjungan  0.666667        1.0   \n",
       "3  Masalah Terkait Pembelian Obat dan Check-in Lo...  1.000000        1.0   \n",
       "\n",
       "     recall  support    kappa  accuracy  \n",
       "0  0.000000        0  0.44186     0.625  \n",
       "1  0.666667        3  0.44186     0.625  \n",
       "2  0.500000        4  0.44186     0.625  \n",
       "3  1.000000        1  0.44186     0.625  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "calculate_classification_metrics(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Masalah Pengelolaan Informasi Vaksinasi',\n",
       "       'Masalah Pengelolaan Informasi Vaksinasi',\n",
       "       'Masalah Pengelolaan Informasi Vaksinasi',\n",
       "       'Masalah Terkait Check-in dan Riwayat Kunjungan',\n",
       "       'Masalah Akses dan Keamanan Data',\n",
       "       'Masalah Pengelolaan Informasi Vaksinasi',\n",
       "       'Masalah Terkait Pembelian Obat dan Check-in Lokasi',\n",
       "       'Masalah Terkait Check-in dan Riwayat Kunjungan'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Masalah Terkait Check-in dan Riwayat Kunjungan',\n",
       "       'Masalah Terkait Check-in dan Riwayat Kunjungan',\n",
       "       'Masalah Pengelolaan Informasi Vaksinasi',\n",
       "       'Masalah Terkait Check-in dan Riwayat Kunjungan',\n",
       "       'Masalah Akses dan Keamanan Data',\n",
       "       'Masalah Pengelolaan Informasi Vaksinasi',\n",
       "       'Masalah Terkait Pembelian Obat dan Check-in Lokasi',\n",
       "       'Masalah Terkait Check-in dan Riwayat Kunjungan'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "model = AutoModel.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world! How are you doing today? Yes today!\n",
      "TestThis is a bold paragraph.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_selected_punctuation(text):\n",
    "    # Match any punctuation except ! and ?\n",
    "    return re.sub(r'[^\\w\\s!?]', '', text)\n",
    "\n",
    "sample_text = \"Hello, world! How are you doing today? Yes, today!\"\n",
    "clean_text = remove_selected_punctuation(sample_text)\n",
    "print(clean_text)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    # Define a regular expression pattern for HTML tags\n",
    "    clean_text = re.sub(r'<.*?>', '', text)\n",
    "    return clean_text\n",
    "\n",
    "# Example usage\n",
    "sample_html = \"<html><head><title>Test</title></head><body><p>This is a <b>bold</b> paragraph.</p></body></html>\"\n",
    "clean_text = remove_html_tags(sample_html)\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class DataCleaning:\n",
    "    def __init__(self,text):\n",
    "        self.text = text\n",
    "\n",
    "    def low_cast_data(self):\n",
    "        self.text = self.text.lower()\n",
    "\n",
    "    def remove_punc(self):\n",
    "        punc = r'[#$%&\\'()*+,\\-./:;<=>@\\[\\\\\\]^_`{|}~]'\n",
    "        self.text = re.sub(punc, '', self.text)\n",
    "\n",
    "    def extra_space(self):\n",
    "        self.text = \" \".join(self.text.split())\n",
    "\n",
    "    def remove_html_tags(self):\n",
    "        self.text = re.sub(r'<.*?>', '', self.text)\n",
    "\n",
    "    def remove_urls(self):\n",
    "        url_pattern = r\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\"\n",
    "        self.text = re.sub(url_pattern, '', self.text)\n",
    "    \n",
    "    def clean(self):\n",
    "        self.low_cast_data()\n",
    "        self.remove_html_tags()\n",
    "        self.remove_punc()\n",
    "        self.extra_space()\n",
    "        self.remove_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1=\"\"\"\n",
    "    Elemen pentingnya adalah \n",
    "    -----\n",
    "    Dear Mba CS Name,\n",
    "\n",
    "    Berikut sy kirimkan PCP untuk TSA Solo.\n",
    "    Tolong dibantu upload.\n",
    "    Thank you.\n",
    "    ------\n",
    "\n",
    "    dan \n",
    "\n",
    "    ----\n",
    "    Selamat Sore Bu Sales Name\n",
    "\n",
    "    Terlampir kami kirimkan PCP bulan April 2024, mohon koreksinya.\n",
    "    Terimakasih.\n",
    "\n",
    "\n",
    "    Salam,\n",
    "\n",
    "    CS Name\n",
    "    ------\n",
    "\"\"\"\n",
    "\n",
    "test_2=\"\"\"\n",
    "<p><strong>Dear Mba Staff Name, : </strong></p><p><strong>Brand Name menginformasikan mengenai email tiket dengan detail sbb : </strong></p><table><tbody><tr><td><strong>Ticket Id</strong></td><td>:</td><td>NM20219999-999</td></tr><tr><td><strong>Priority</strong></td><td>:</td><td>NORMAL</td></tr><tr><td><strong>Status</strong></td><td>:</td><td>PENDING</td></tr><tr><td><strong>Inbound</strong></td><td>:</td><td style=\"width: 70%; word-wrap:break-word ;\" >Bpk. Customer Name, end user area Jember, Jawa Tengah dgn No Hp 08123456789, <BR>melalui DM Instagram  Pak Customer Name bertanya sbb :<BR>  min mau tanya klo Cat Brand 2T itu warna isinya yg asli apa ya? Saya beli Brand di 3 toko yang berbeda, toko ke 1 dan ke 2 warna putih & Toko  ke 3  kok warnannya kuning ya ? #Mohon infonya. <BR>Foto terlampir, akan kami kirimkan by email.<BR>.<BR> Terima kasih.<BR></td></tr><tr><td><strong>Category</strong></td><td>:</td><td>MEMBER</td></tr><tr><td><strong>Type</strong></td><td>:</td><td>NON MEMBER</td></tr><tr><td><strong>View Detail</strong></td><td>:</td><td><a href=\"brand-name.co.id?paramId=NM20219999-999\">View Inbound Detail</a></td></tr></tbody></table><p>&nbsp;</p><p>&nbsp;</p><p>Kami tunggu informasinya, terimakasih atas perhatiannya.</p><p>&nbsp;</p><p>Salam Hangat,</p><p>Brand Name</p>\n",
    "\"\"\"\n",
    "\n",
    "test_3=\"\"\"\n",
    "Dear tim,\n",
    "\n",
    "Thank you.\n",
    "\n",
    "On Mon, Nov 15, 2021 at 9:39 AM <client@email.id> wrote:\n",
    "\n",
    "> Dear Ibu Client Name,\n",
    ">\n",
    ">\n",
    ">\n",
    "> *Terlampir kami sampaikan Logbook Case dari Medsos Per 12 November 2021,\n",
    "> Mohon dapat diterima dengan baik.*\n",
    ">\n",
    ">\n",
    ">\n",
    "> Terima kasih,\n",
    ">\n",
    ">\n",
    ">\n",
    ">\n",
    "> Salam Sukses\n",
    ">\n",
    ">\n",
    ">\n",
    ">\n",
    ">\n",
    "> From: client@email.id <client@email.id>\n",
    "> Sent: 08 November 2023 11:18\n",
    "> To: 'Client Name' <client@name.biz>\n",
    "> Cc: 'CC Name' <cc@name.biz>\n",
    "> Subject: [CLIENT] Customer Services 05 November 2023\n",
    ">\n",
    ">\n",
    ">\n",
    "> Dear Ibu Client Name,\n",
    ">\n",
    ">\n",
    ">\n",
    "> *Terlampir kami sampaikan Logbook Case dari Medsos Per 05 November 2021,\n",
    "> Mohon dapat diterima dengan baik.*\n",
    ">\n",
    ">\n",
    ">\n",
    "> Terima kasih,\n",
    ">\n",
    ">\n",
    ">\n",
    ">\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDear tim,\\n\\nThank you.\\n\\nOn Mon, Nov 15, 2021 at 9:39 AM <client@email.id> wrote:\\n\\n> Dear Ibu Client Name,\\n>\\n>\\n>\\n> *Terlampir kami sampaikan Logbook Case dari Medsos Per 12 November 2021,\\n> Mohon dapat diterima dengan baik.*\\n>\\n>\\n>\\n> Terima kasih,\\n>\\n>\\n>\\n>\\n> Salam Sukses\\n>\\n>\\n>\\n>\\n>\\n> From: client@email.id <client@email.id>\\n> Sent: 08 November 2023 11:18\\n> To: 'Client Name' <client@name.biz>\\n> Cc: 'CC Name' <cc@name.biz>\\n> Subject: [CLIENT] Customer Services 05 November 2023\\n>\\n>\\n>\\n> Dear Ibu Client Name,\\n>\\n>\\n>\\n> *Terlampir kami sampaikan Logbook Case dari Medsos Per 05 November 2021,\\n> Mohon dapat diterima dengan baik.*\\n>\\n>\\n>\\n> Terima kasih,\\n>\\n>\\n>\\n>\\n\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coba = DataCleaning(test_3)\n",
    "coba.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dear tim thank you on mon nov 15 2021 at 939 am wrote dear ibu client name terlampir kami sampaikan logbook case dari medsos per 12 november 2021 mohon dapat diterima dengan baik terima kasih salam sukses from clientemailid sent 08 november 2023 1118 to client name cc cc name subject client customer services 05 november 2023 dear ibu client name terlampir kami sampaikan logbook case dari medsos per 05 november 2021 mohon dapat diterima dengan baik terima kasih'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coba.clean()\n",
    "coba.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI11\\AppData\\Local\\Temp\\ipykernel_23916\\2144035880.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n",
      "C:\\Users\\MSI11\\AppData\\Local\\Temp\\ipykernel_23916\\2144035880.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}\n"
     ]
    }
   ],
   "source": [
    "#tokenized_train = tokenizer(X_train.tolist(), padding = True, truncation = True, return_tensors=\"pt\")\n",
    "#tokenized_val = tokenizer(X_test.tolist() , padding = True, truncation = True,  return_tensors=\"pt\").to(device)\n",
    "#\n",
    "##move on device (GPU)\n",
    "#tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n",
    "#tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▍         | 1/22 [01:18<27:32, 78.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 2/22 [02:44<27:38, 82.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▎        | 3/22 [03:54<24:23, 77.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 4/22 [05:02<22:04, 73.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 5/22 [06:12<20:25, 72.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 6/22 [07:25<19:21, 72.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 7/22 [08:34<17:47, 71.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▋      | 8/22 [09:44<16:31, 70.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 9/22 [10:52<15:11, 70.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▌     | 10/22 [12:03<14:04, 70.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 11/22 [13:12<12:48, 69.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▍    | 12/22 [14:25<11:47, 70.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 13/22 [15:43<10:56, 72.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▎   | 14/22 [16:51<09:32, 71.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 15/22 [18:05<08:26, 72.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 16/22 [19:24<07:25, 74.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 17/22 [20:47<06:24, 77.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 18/22 [22:06<05:10, 77.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▋ | 19/22 [23:25<03:54, 78.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 20/22 [24:48<02:38, 79.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▌| 21/22 [26:10<01:20, 80.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 22/22 [26:18<00:00, 71.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/22 batches, 22 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches:  17%|█▋        | 1/6 [01:33<07:48, 93.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/6 batches, 6 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 2/6 [02:58<05:53, 88.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/6 batches, 6 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 3/6 [04:27<04:26, 88.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/6 batches, 6 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 4/6 [05:48<02:50, 85.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/6 batches, 6 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 5/6 [07:13<01:25, 85.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/6 batches, 6 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 6/6 [07:37<00:00, 76.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/6 batches, 6 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def batch_data(tokenizer, texts,max_length=512, batch_size=100):\n",
    "    # Tokenize the text data\n",
    "    tokenized = tokenizer(texts, max_length=max_length,padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Create a dataset from tensors\n",
    "    dataset = TensorDataset(tokenized['input_ids'], tokenized['attention_mask'], tokenized['token_type_ids'])\n",
    "    \n",
    "    # Create a DataLoader\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = batch_data(tokenizer, X_train.tolist())\n",
    "val_loader = batch_data(tokenizer, X_test.tolist())\n",
    "\n",
    "# Processing in batches\n",
    "def process_batches(data_loader, model, device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    total_batches = len(data_loader)\n",
    "    processed_batches = 0  # Counter to track processed batches\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, token_type_ids in tqdm(data_loader, desc=\"Processing batches\"):\n",
    "            inputs = {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'token_type_ids': token_type_ids\n",
    "            }\n",
    "            output = model(**inputs)\n",
    "            # Accessing the last hidden state and moving it to CPU\n",
    "            outputs.append(output.last_hidden_state.cpu())\n",
    "            \n",
    "            remaining_batches = total_batches - processed_batches\n",
    "            print(f\"Processed {processed_batches}/{total_batches} batches, {remaining_batches} remaining\")\n",
    "    # Concatenating the results across batches\n",
    "    return torch.cat(outputs, dim=0)\n",
    "\n",
    "# Process training and validation data\n",
    "hidden_train = process_batches(train_loader, model, device)\n",
    "hidden_val = process_batches(val_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 44870651904 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m   hidden_train \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtokenized_train) \u001b[39m#dim : [batch_size(nr_sentences), tokens, emb_dim]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m   hidden_val \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtokenized_val)\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1006\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1006\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1009\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1010\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[0;32m   1013\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m   1014\u001b[0m     embedding_output,\n\u001b[0;32m   1015\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m   1024\u001b[0m )\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:232\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    229\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_ids\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)\n\u001b[0;32m    233\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    235\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    164\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\MSI11\\.conda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 44870651904 bytes."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  hidden_train = model(**tokenized_train) #dim : [batch_size(nr_sentences), tokens, emb_dim]\n",
    "  hidden_val = model(**tokenized_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_train = hidden_train[:,0,:]\n",
    "cls_val = hidden_val[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6797,  2.5192,  0.7429,  ..., -0.3515, -0.2583, -0.0498],\n",
       "         [ 0.0351, -0.2479, -0.2011,  ..., -1.4289,  0.2640, -0.3772],\n",
       "         [-0.6866,  1.0888,  1.0105,  ...,  0.6559,  1.2218, -1.4541],\n",
       "         ...,\n",
       "         [-0.1078,  1.9288,  0.1102,  ..., -0.2184,  0.7896, -0.3703],\n",
       "         [-0.1581,  1.6967, -0.3239,  ..., -0.1279,  0.5983, -0.3087],\n",
       "         [-0.3139,  1.4930, -0.3406,  ..., -0.1692,  0.4193, -0.4457]],\n",
       "\n",
       "        [[-0.1692,  2.2867,  0.7424,  ...,  0.7720,  0.5473,  0.7915],\n",
       "         [-0.4439,  1.0658,  1.3666,  ...,  0.6507, -0.1035, -0.3604],\n",
       "         [-1.5802,  1.1258, -0.4194,  ...,  0.1442,  0.3902,  2.5361],\n",
       "         ...,\n",
       "         [-1.3393,  1.6026,  1.7633,  ...,  1.6469,  0.5346, -0.3368],\n",
       "         [-1.1220,  1.4857,  2.2326,  ...,  1.3308,  0.8098, -0.4000],\n",
       "         [-1.2463,  1.3982,  2.0396,  ...,  1.3764,  0.5045, -0.2983]],\n",
       "\n",
       "        [[-1.0845,  2.2819,  0.5672,  ..., -0.4812,  0.0136,  0.0623],\n",
       "         [-1.2719,  1.9638,  0.2880,  ..., -0.7861, -0.0155,  2.0960],\n",
       "         [-0.7354,  1.3379,  0.6911,  ...,  0.4713, -0.6072, -0.5027],\n",
       "         ...,\n",
       "         [-0.4554,  1.7060,  0.1503,  ..., -0.5825,  0.5598, -0.2528],\n",
       "         [-0.3819,  1.5604, -0.2254,  ..., -0.5477,  0.4710, -0.0711],\n",
       "         [-0.4630,  1.6538, -0.2596,  ..., -0.7027,  0.0871, -0.3359]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.2899,  1.2441,  0.7396,  ..., -0.4575, -0.3725, -0.1645],\n",
       "         [-0.8233,  1.0656, -0.1423,  ...,  0.0830, -0.1694,  0.1991],\n",
       "         [ 0.0541,  0.6372, -0.6339,  ...,  0.3714,  0.1628,  1.0286],\n",
       "         ...,\n",
       "         [ 0.1381,  0.7077,  1.5002,  ...,  0.2457,  0.2190,  0.8018],\n",
       "         [-0.4353, -0.0320,  2.0019,  ..., -0.3377,  0.6608,  0.6558],\n",
       "         [-0.7498, -0.0325,  1.1844,  ..., -0.6225,  0.2007,  0.7934]],\n",
       "\n",
       "        [[-0.4535,  3.4327, -0.1789,  ...,  0.4737, -0.1875,  0.3844],\n",
       "         [-0.3745,  0.3510,  0.5905,  ..., -0.6061, -0.5667, -0.5397],\n",
       "         [-0.5885,  0.7238, -0.1900,  ..., -0.1710,  0.2644,  0.2561],\n",
       "         ...,\n",
       "         [-1.4998,  1.1285, -0.0654,  ...,  0.4824, -0.4109, -0.2735],\n",
       "         [-0.9773,  0.7797,  0.2250,  ...,  0.3216, -0.6088,  0.2166],\n",
       "         [-0.8988,  0.8592, -0.6058,  ...,  1.0414, -0.2803,  0.4660]],\n",
       "\n",
       "        [[-1.6067,  1.8498, -0.0730,  ..., -0.0409, -0.3559,  0.6140],\n",
       "         [-2.5683,  0.5330,  1.0996,  ...,  1.2200,  0.9245,  0.9884],\n",
       "         [-0.3878, -0.2294,  0.2922,  ..., -0.1074,  0.4401,  0.8019],\n",
       "         ...,\n",
       "         [-1.3279,  0.7970,  0.5841,  ..., -0.9003,  0.1521,  0.1872],\n",
       "         [-1.1691,  0.6170,  0.4320,  ..., -0.8494,  0.1908,  0.3108],\n",
       "         [-1.2733,  0.4769,  0.4687,  ..., -0.8157,  0.0717,  0.1094]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. RandomForestClassifier expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      3\u001b[0m rf \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m----> 4\u001b[0m rf\u001b[39m.\u001b[39;49mfit(hidden_train,y_train)\n\u001b[0;32m      5\u001b[0m rf\u001b[39m.\u001b[39mscore(cls_val,y_test) \n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    346\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    348\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m     )\n\u001b[0;32m    920\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    921\u001b[0m     _assert_all_finite(\n\u001b[0;32m    922\u001b[0m         array,\n\u001b[0;32m    923\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. RandomForestClassifier expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(cls_train,y_train)\n",
    "rf.score(cls_val,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9488636363636364"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xg_ = XGBClassifier()\n",
    "xg_.fit(hidden_train,y_train_)\n",
    "xg_.score(cls_val,y_test_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI11\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9602272727272727"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_ = svm.LinearSVC(C=1.0, class_weight=\"balanced\")\n",
    "sv_.fit(hidden_train,y_train_)\n",
    "sv_.score(cls_val,y_test_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI11\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   f_score  precision  recall  support     kappa  accuracy\n",
       "0      0  0.000000        0.0     0.0        0  0.794872     0.875\n",
       "1      1  0.888889        1.0     0.8        5  0.794872     0.875\n",
       "2      2  1.000000        1.0     1.0        2  0.794872     0.875\n",
       "3      3  1.000000        1.0     1.0        1  0.794872     0.875"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = sv_.predict(cls_val)\n",
    "calculate_classification_metrics(preds, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 1, 1, 3, 2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 0, 1, 3, 2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masalah Akses dan Keamanan Data</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masalah Pengelolaan Informasi Vaksinasi</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masalah Terkait Check-in dan Riwayat Kunjungan</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masalah Terkait Pembelian Obat dan Check-in Lo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               class   f_score  precision  \\\n",
       "0                    Masalah Akses dan Keamanan Data  0.000000       0.00   \n",
       "1            Masalah Pengelolaan Informasi Vaksinasi  0.333333       0.25   \n",
       "2     Masalah Terkait Check-in dan Riwayat Kunjungan  0.800000       1.00   \n",
       "3  Masalah Terkait Pembelian Obat dan Check-in Lo...  1.000000       1.00   \n",
       "\n",
       "     recall  support     kappa  accuracy  \n",
       "0  0.000000        2  0.319149       0.5  \n",
       "1  0.500000        2  0.319149       0.5  \n",
       "2  0.666667        3  0.319149       0.5  \n",
       "3  1.000000        1  0.319149       0.5  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rf.predict(cls_val)\n",
    "calculate_classification_metrics(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from src.model import *\n",
    "from src.preprocessing import *\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "model = AutoModel.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "class Preprocessing:\n",
    "\n",
    "    def __init__(self):\n",
    "        df=pd.read_csv(\"Dataset/health.csv\",sep=\";\")[[\"text\",\"category\"]]\n",
    "        self.X=df[\"text\"].values\n",
    "        self.labels = df['category'].values\n",
    "\n",
    "    #def clean_data(self):\n",
    "    #    self.X = batch_clean(self.X)\n",
    "    #    self.labels = batch_clean(self.labels)\n",
    "    \n",
    "    def split_data(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def tokenizing(self):\n",
    "        self.train_loader = batch_tokenize_data(tokenizer, self.X_train.tolist())\n",
    "        self.val_loader = batch_tokenize_data(tokenizer, self.X_test.tolist())\n",
    "\n",
    "    def encoding(self):\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.y_train_ = self.encoder.fit_transform(self.y_train)\n",
    "        self.y_test_ = self.encoder.transform(self.y_test)\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.train_loader, self.val_loader, self.y_train_, self.y_test_\n",
    "    \n",
    "\n",
    "class Modeling:\n",
    "    models= {\n",
    "        \"rf\": RandomForestClassifier(),\n",
    "        \"xgb\": XGBClassifier(),\n",
    "        \"svm\": LinearSVC()\n",
    "    }\n",
    "\n",
    "    def __init__(self,train_loader,val_loader,y_train_,y_test_,**kwargs):\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.y_train_ = y_train_\n",
    "        self.y_test_ = y_test_\n",
    "\n",
    "    def get_hidden_clf(self):\n",
    "        self.cls_train = get_cls_hidden_state_batches(self.train_loader, model)[:,0,:]\n",
    "        self.cls_val = get_cls_hidden_state_batches(self.val_loader, model)[:,0,:]\n",
    "        print(self.cls_train)\n",
    "        print(self.cls_val)\n",
    "\n",
    "    def train_models(self):\n",
    "        for key, model in self.models.items():\n",
    "            model.fit(self.cls_train,self.y_train_)\n",
    "    \n",
    "    def evaluate_models(self):\n",
    "        preds = {key: model.predict(self.cls_val) for key,model in self.models.items()}\n",
    "        models_score = compare_model(preds,self.y_test_)\n",
    "        print(models_score)\n",
    "\n",
    "    def get_models():\n",
    "        return self.models\n",
    "\n",
    "def create_model():\n",
    "    preprocess = Preprocessing()\n",
    "    preprocess.split_data()\n",
    "    preprocess.tokenizing()\n",
    "    preprocess.encoding()\n",
    "\n",
    "    modeling = Modeling(**vars(preprocess))\n",
    "    print(vars(preprocess).keys())\n",
    "    modeling.get_hidden_clf()\n",
    "    modeling.train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X', 'labels', 'X_train', 'X_test', 'y_train', 'y_test', 'train_loader', 'val_loader', 'encoder', 'y_train_', 'y_test_'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3553,  1.9224,  0.4365,  ..., -0.1288, -0.8967,  0.0188],\n",
      "        [ 0.0423,  1.9153,  0.3772,  ..., -0.1001, -0.3121,  0.6772],\n",
      "        [ 0.1365,  1.5206,  0.8567,  ...,  0.3454, -0.5670,  0.7800],\n",
      "        ...,\n",
      "        [ 0.5146,  1.9118,  1.2749,  ...,  0.7630, -1.0019,  0.4778],\n",
      "        [ 0.3047,  1.3959,  0.7638,  ...,  0.1765, -1.0451,  0.1686],\n",
      "        [ 1.2877,  1.7488,  0.4171,  ..., -0.7688, -0.6170,  0.2812]])\n",
      "tensor([[ 0.2775,  1.8993,  1.1300,  ..., -0.0340, -1.1617,  0.3588],\n",
      "        [ 0.7101,  1.8733,  0.1727,  ..., -0.2653, -0.2282,  0.6452],\n",
      "        [ 1.0083,  2.2007,  1.0124,  ...,  0.5773, -0.9310,  0.3643],\n",
      "        ...,\n",
      "        [ 0.7505,  1.5821,  1.1316,  ...,  0.1237, -0.9783,  0.5782],\n",
      "        [ 0.3919,  2.0519,  1.3482,  ...,  0.4941, -0.7749,  0.4853],\n",
      "        [ 0.5701,  1.6949,  0.5827,  ...,  0.5630, -1.1196,  0.1240]])\n"
     ]
    }
   ],
   "source": [
    "create_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
